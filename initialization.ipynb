{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will provide you with an introduction to the repository and assist you in getting your data set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. tensor_hero module\n",
    "\n",
    "I highly recommend parsing through each file in the tensor_hero module and reading through the functions and their docstrings.\n",
    "\n",
    "The tensor_hero module is defined in the tensor_hero folder. It contains a suite of useful functions which you can import easily. Here's how that might work:\n",
    "\n",
    "    from tensor_hero.preprocessing.data import populate_processed_folder\n",
    "\n",
    "    <do something with populate_processed_folder>\n",
    "\n",
    "If you wanted to see how populated_processed_folder() works, just navigate to\n",
    "> ./tensor_hero/preprocessing/data.py\n",
    "\n",
    "then read the docstring about populate_processed_folder()\n",
    "\n",
    "Writing the line above will work in this jupyter notebook because its working directory contains the tensor_hero module, i.e. the folder structure is\n",
    "\n",
    "tensor-hero *(this is the working directory)*\\\n",
    "-> tensor_hero *(this is the module)* \\\n",
    "-> \\<other folders and scripts\\> \\\n",
    "-> initialization.ipynb *(the script is not in the same directory as the module)*\n",
    "\n",
    "If you wanted to use the tensor hero module in a directory other than the repo's home directory, you'll need to add the repo's home directory to the system's path explicitly. Let's say the folder structure was\n",
    "\n",
    "\n",
    "tensor-hero \\\n",
    "-> tensor_hero *(this is the module)* \\\n",
    "-> \\<other folders and scripts\\> \\\n",
    "-> some_other_folder *(this is the working directory)*\\\n",
    "-----> initialization.ipynb *(the script is not in the same directory as the module)*\n",
    "\n",
    "Now the working directory doesn't contain the tensor_hero module, so you need to add the top-level directory to your system path. This would look something like this:\n",
    "\n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    sys.path.insert(1, str(Path.cwd().parent))\n",
    "    from tensor_hero.visualization import slice_notes, plot_chart\n",
    "\n",
    "or, in pseudocode\n",
    "\n",
    "    import pathlib library, which makes it easy to work with filepaths\n",
    "    import sys, which will be used to append to the system path\n",
    "    append the directory outside of this one (Path.cwd().parent) to the system path\n",
    "    import tensor_hero functions\n",
    "\n",
    "If this was a .py file rather than .ipynb, we would need to append the current working directory to the path:\n",
    "\n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    sys.path.insert(1, str(Path.cwd()))\n",
    "    from tensor_hero.visualization import slice_notes, plot_chart\n",
    "\n",
    "Please be sure to use the pathlib library rather than hardcoding your own computer's filepath when doing these import statements\n",
    "\n",
    "Now, let's see some of the things you can do with this module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the audio and notes of a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load a song\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tensor_hero.visualization import plot_chart, slice_notes # some visualization functions\n",
    "\n",
    "song_dir = Path.cwd() / 'example_song'  # This example directory is good for experimenting with dummy data\n",
    "\n",
    "print('Here are the files in the song directory:')\n",
    "print(os.listdir(song_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- album.png -> album art\n",
    "- notes.chart -> raw chart file\n",
    "- notes.npy -> notes array\n",
    "- notes_simplified.npy -> simplified notes array\n",
    "- separated.ogg -> source separated audio file\n",
    "- song.ini -> song metadata for Clone Hero use\n",
    "- song.ogg -> raw audio file\n",
    "- spectrogram.npy -> spectrogram from raw audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print a few lines of the .chart file to see which song we're dealing with\n",
    "\n",
    "with open(song_dir / 'notes.chart', 'r', encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f.readlines()):\n",
    "        print(line)\n",
    "        if idx > 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Okay it looks like we're going to be investigating the song Ouray.\n",
    "# Let's plot a subsection of it's notes\n",
    "\n",
    "# Load the spectrogram and notes\n",
    "spec = np.load(song_dir / 'spectrogram.npy')        # Recall, spectrograms are 2D numpy arrays detailing frequency over time\n",
    "notes = np.load(song_dir / 'notes_simplified.npy')  # Notes arrays detail notes present at every time bin in the song\n",
    "\n",
    "print('Spectrogram and notes have the same length in the time dimension:')\n",
    "print(f'spectrogram shape: {spec.shape}')\n",
    "print(f'notes shape: {notes.shape}')\n",
    "\n",
    "# plot_chart() is useful for plotting spectrograms and printing guitar hero notes\n",
    "# slice_notes() cuts the notes or audio between a specified start and end point in seconds\n",
    "_ = plot_chart(candidate=slice_notes(notes, 5, 8), audio=slice_notes(spec, 5, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slice_notes() can be used on both notes arrays and audio.\n",
    "\n",
    "What is the notes array though? Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_section = slice_notes(notes, 5, 8)  # The notes array between seconds 5 and 8 of the song\n",
    "print('raw notes array encompassing 3 seconds of song data:')\n",
    "print(notes_section)\n",
    "\n",
    "print('\\nLet\\'s highlight just the ticks with notes, only for the first 1 second of song data.')\n",
    "print('tick : note')\n",
    "for i, x in enumerate(list(notes_section)):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if x:\n",
    "        print(f'{i} : {int(x)}')\n",
    "        \n",
    "print('\\nYou could read this as: \\nred note at 180ms \\ngreen note at 440ms \\nred note at 700ms \\ngreen note at 960ms')\n",
    "_ = plot_chart(candidate=notes_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Machine Learning\n",
    "\n",
    "When we give our data as input to the machine learning model, we have to transform it in a way that the model can understand. We follow the heuristic of Hawthorne et al. in Sequence-to-Sequence Piano Transcription with transformers\n",
    "\n",
    "We represent each note as two separate pieces of information: a time step and a note. When comparing output, the model sees the time step, then it sees the note corresponding to that time step. This might seem counterintuitive, but the transformer model actually does a really good job of learning to output time steps then note selections in sequential order.\n",
    "\n",
    "A ground truth vector might looks something like this:\n",
    "\n",
    "    [432, 36, 4, 89, 0, 433, 434, 434, 434]\n",
    "\n",
    "which can be translated as\n",
    "\n",
    "    [<start of sequence>, <40ms from start>, <orange note>, <570ms from start>, <green note>, <end of sequence>, <pad>, <pad>, <pad>]\n",
    "\n",
    "See tensor-hero/Documentation/'format of model 1 data.txt' for more information.\n",
    "\n",
    "Each spectrogram input is limited to 400 frames, or 4 seconds of audio data and time bins are predicted relative to the start of that audio segment. During inference, songs are chopped into 4 second chunks, predicted, then concatenated.\n",
    "\n",
    "As an exercise, let's convert some portion of a notes array to this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_hero.preprocessing.model import __notes_to_output_space, __prepare_notes_tensor\n",
    "\n",
    "print('Original notes array:')\n",
    "print(notes_section)\n",
    "\n",
    "# We convert the notes arrays in a sequence of two functions\n",
    "# Note that the prepended double underscore typically means \"for internal use\" i.e. these\n",
    "# are functions that are not usually imported\n",
    "prepared_notes = __notes_to_output_space(notes_section)\n",
    "prepared_notes = __prepare_notes_tensor(prepared_notes)\n",
    "\n",
    "print('\\nReformatted notes:')\n",
    "print(prepared_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we add the padding during the dataloading process\n",
    "\n",
    "Now, let's check out the model inference process. We'll use a (super dumb) model we've already trained. These saved models can be found in\n",
    ">tensor-hero/model/'saved models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# First, let's load the model's parameters and define a Transformer model with them\n",
    "# Let's take a look at these parameters, they're stored in a dictionary\n",
    "\n",
    "model_path = Path.cwd() / 'model' / 'saved models' / 'model12'\n",
    "with open(model_path / 'params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    \n",
    "print(json.dumps(params, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_hero.model import Transformer\n",
    "import torch\n",
    "\n",
    "# We use these parameters to define the skeleton of the model, then load the weights into it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device = {device}')\n",
    "\n",
    "# Model hyperparameters are derived from the params dictionary\n",
    "trg_vocab_size = params['trg_vocab_size']\n",
    "embedding_size = params['embedding_size']\n",
    "num_heads = params['num_heads']\n",
    "num_encoder_layers = params['num_encoder_layers']\n",
    "num_decoder_layers = params['num_decoder_layers']\n",
    "dropout = params['dropout']\n",
    "max_len = params['max_trg_len']\n",
    "forward_expansion = params['embedding_size']*params['forward_expansion']\n",
    "\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    trg_vocab_size,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)  # Always send the model to the GPU\n",
    "\n",
    "# Load the weights into the model\n",
    "model.load_state_dict(torch.load(model_path / 'model12.pt'))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Looks like we're ready to do inference. We're going to send the model's output to\n",
    ">tensor-hero/example_song/generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_hero.inference import full_song_prediction\n",
    "\n",
    "# Define the folder to hold the output of the model\n",
    "outfolder = Path.cwd() / 'example_song' / 'generated'\n",
    "audio_file = song_dir / 'song.ogg'\n",
    "\n",
    "# We have to define some things for the .chart file so it's actually playable\n",
    "# just some dummy metadata for now\n",
    "song_metadata = {'Name' : 'model12',\n",
    "                'Artist' : 'Forrest',       # Forrest is the honorary author of all of our output\n",
    "                'Charter' : 'tensorhero',\n",
    "                'Offset' : 0,\n",
    "                'Resolution' : 192,\n",
    "                'Genre' : 'electronic',\n",
    "                'MediaType' : 'cd',\n",
    "                'MusicStream' : 'song.ogg'}\n",
    "\n",
    "_ = full_song_prediction(song_path = audio_file,\n",
    "                         model=model,\n",
    "                         device=device,\n",
    "                         sos_idx=432,\n",
    "                         max_len=500,\n",
    "                         song_metadata=song_metadata,\n",
    "                         outfolder=outfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting up training data\n",
    "\n",
    "Importantly, the programs in this repo assume a particular directory structure for the  training data. This is how it should be initialized:\n",
    "\n",
    "Training Data \\\n",
    "-> Unprocessed \\\n",
    "-> Processed\n",
    "\n",
    "**Place 'Training Data' in the same directory as this repository.** Make sure you add it to the .gitignore if it isn't already there so you don't accidentally upload all the training data to GitHub. \n",
    "\n",
    "The directories should be empty at this point. To populate them, navigate to this link, https://docs.google.com/spreadsheets/d/13B823ukxdVMocowo1s5XnT3tzciOfruhUVePENKc01o/edit#gid=0 , and download the following track packs:\n",
    "- Angevil Hero II\n",
    "- Anti Hero\n",
    "- Anti Hero 2\n",
    "- Community Track Pack 6\n",
    "- Digitizer\n",
    "- Facelift Pack 1\n",
    "- Facelift Pack 2\n",
    "- Focal Point\n",
    "- Guitar Hero X\n",
    "- Paradigm\n",
    "\n",
    "The track packs should be unzipped into the Unprocessed folder\n",
    "> Training Data/Unprocessed\n",
    "\n",
    "Once the track packs are unzipped, **run the cell at the end of this notebook to populate the processed folder, this might take a while.**\n",
    "\n",
    "Before then, take some time to check out this introduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell after the track packs are downloaded and unzipped to preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To process the training data, we will use the populated_processed_folder()\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tensor_hero.preprocessing.data import populate_processed_folder, populate_with_simplified_notes\n",
    "\n",
    "unprocessed_path = Path.cwd() / 'Training Data' / 'Unprocessed'\n",
    "processed_path = Path.cwd() / 'Training Data' / 'Processed'\n",
    "\n",
    "assert (os.path.isdir(unprocessed_path) and os.path.isdir(processed_path)), 'ERROR: Place \"Training Data\" folder in this directory'\n",
    "\n",
    "processing_data = populate_processed_folder(unprocessed_data_path=unprocessed_path,\n",
    "                                            processed_data_path=processed_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial processing, we need to simplify the notes arrays into our current format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_with_simplified_notes(processed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Misc useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all the .ogg files in the training data\n",
    "\n",
    "(You have to have the training data set up before this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_hero.preprocessing.data import get_list_of_ogg_files\n",
    "\n",
    "# ogg_file_paths contains unprocessed paths to ogg files, processed_paths contains their processed\n",
    "# analogs.\n",
    "ogg_file_paths, processed_paths = get_list_of_ogg_files(unprocessed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the spectrogram of some audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.display import specshow\n",
    "from tensor_hero.preprocessing.audio import compute_mel_spectrogram\n",
    "\n",
    "audio_file = song_dir / 'song.ogg'\n",
    "spec = compute_mel_spectrogram(audio_file)\n",
    "\n",
    "specshow(spec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
