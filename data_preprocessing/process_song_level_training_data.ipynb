{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made directory X:\\Training Data\\training_ready\n",
      "made directory X:\\Training Data\\training_ready\\train\n",
      "made directory X:\\Training Data\\training_ready\\val\n",
      "made directory X:\\Training Data\\training_ready\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "from tensor_hero.preprocessing.data import get_list_of_ogg_files\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "def __process_spectrogram(spec):\n",
    "    '''\n",
    "    Normalizes spectrogram in [0,1]\n",
    "    \n",
    "    ~~~~ ARGUMENTS ~~~~\n",
    "    - spec (2D numpy array):padded spectrogram, loaded from spectrogram.npy in processed folder\n",
    "    \n",
    "    ~~~~ RETURNS ~~~~\n",
    "    - 2D numpy array : Normalized spectrogram\n",
    "    '''\n",
    "    spec = (spec+80) / 80   # Regularize\n",
    "    return spec\n",
    "\n",
    "def __notes_to_output_space(notes):\n",
    "    '''\n",
    "    Takes a notes array as input, and outputs a matrix of numpy arrays in the output format specified\n",
    "    by sequence to sequence piano transcription.\n",
    "    \n",
    "    ~~~~ ARGUMENTS ~~~~\n",
    "    - notes (1D numpy array) : notes array\n",
    "    \n",
    "    ~~~~ RETURNS ~~~~\n",
    "    - 2D numpy array:\n",
    "        - Y axis is sequential note events, with each new row being a time event, then note event\n",
    "        - X axis is one hot encoded arrays, where the index will be fed into the transformer as output\n",
    "    '''\n",
    "    # Get number of notes in array\n",
    "    num_notes = np.count_nonzero(notes)\n",
    "\n",
    "    # Convert \"218\" i.e. open notes to\n",
    "    notes = np.where(notes == 218, 32, notes)\n",
    "\n",
    "    # Construct a numpy array of the proper dimensionality\n",
    "    # 32 positions for the one hot encoded notes, 400 for the absolute time\n",
    "    formatted = np.zeros(shape=(num_notes*2, 32 + 400))\n",
    "\n",
    "    # Loop through notes array and populate formatted\n",
    "    i = 0\n",
    "    for time_pos, x in enumerate(notes):\n",
    "        if x != 0:\n",
    "            formatted[2*i, time_pos+32] = 1  # One hot encode the time step\n",
    "            formatted[2*i+1, int(x)-1] = 1   # One hot encode the note\n",
    "            i += 1\n",
    "            \n",
    "    return formatted\n",
    "\n",
    "def __formatted_notes_to_indices(notes):\n",
    "    '''\n",
    "    Takes formatted notes and returns a 1D array of indices, reverse one hot operation.\n",
    "    Helper function for __prepare_notes_tensor()\n",
    "    ~~~~ ARGUMENTS ~~~~\n",
    "    notes (1D numpy array): formatted notes, as output by __notes_to_output_space()\n",
    "    \n",
    "    ~~~~ RETURNS ~~~~\n",
    "    indices (1D numpy array): \n",
    "        - de-one hot encoded indices of note event series.\n",
    "        - the format is [time, note, time, note, etc...] \n",
    "    '''\n",
    "    indices = np.argwhere(notes == 1)\n",
    "    indices = indices[:,-1].flatten()\n",
    "    return indices\n",
    "\n",
    "def __prepare_notes_tensor(notes):\n",
    "    '''\n",
    "    Takes formatted notes and converts them to the format suitable for PyTorch's transformer model.\n",
    "    Helper function for populate_model_1_training_data()\n",
    "    \n",
    "    ~~~~ ARGUMENTS ~~~~\n",
    "    - notes (1D numpy array): formatted notes, as output by __notes_to_output_space()\n",
    "    \n",
    "    ~~~~ RETURNS ~~~~\n",
    "    - 1D numpy array : notes with format [<sos>, time, note, time, note, etc..., <eos>]\n",
    "    '''\n",
    "    # Concatenate two extra dimensions for SOS and EOS to self.notes\n",
    "    notes_append = np.zeros(shape=(notes.shape[0], 2))\n",
    "    notes = np.c_[notes, notes_append]\n",
    "    # Add a row at the beginning and end of note for <sos>, <eos>\n",
    "    notes_append = np.zeros(shape=(1,notes.shape[1]))\n",
    "    notes = np.vstack([notes_append, notes, notes_append])\n",
    "    # Add proper values to self.notes\n",
    "    notes[0,-2] = 1  # <sos>\n",
    "    notes[-1,-1] = 1 # <eos>\n",
    "    notes = __formatted_notes_to_indices(notes)\n",
    "    # Note: pytorch tensors don't compress as well as numpy arrays\n",
    "    # notes = torch.tensor(notes, dtype=torch.float)\n",
    "    return notes\n",
    "\n",
    "'''\n",
    "Takes a directory of processed song level training data and slices each song into 4 second segments.\n",
    "Splits train, test, and validation at the song level.\n",
    "\n",
    "File structure looks like\n",
    "\n",
    "Training_Data\n",
    "|\n",
    "|----training_ready\n",
    "    |----train\n",
    "    |   |----<song name 1>\n",
    "    |   |   |----notes\n",
    "    |   |   |   |----1.npy\n",
    "    |   |   |   |----2.npy\n",
    "    |   |   |----spectrograms\n",
    "    |   |   |   |----1.npy\n",
    "    |   |   |   |----2.npy\n",
    "    |   |\n",
    "    |   |----<song name 2>\n",
    "    |----test\n",
    "    |----val\n",
    "'''\n",
    "\n",
    "segment_length = 400 # segment length in number of 10ms time slices\n",
    "training_data_path = Path(r'X:\\Training Data')\n",
    "train_val_test_probs = [0.95, 0.025, 0.025]  # Probabilities of song being placed in [train, val, test]\n",
    "COLAB = True\n",
    "unprocessed_path = training_data_path / 'Unprocessed'\n",
    "train_path = training_data_path / 'training_ready' / 'train'\n",
    "val_path = training_data_path / 'training_ready' / 'val'\n",
    "test_path = training_data_path / 'training_ready' / 'test'\n",
    "\n",
    "# Make directories if they don't exist\n",
    "if not os.path.isdir(training_data_path / 'training_ready'):\n",
    "    os.mkdir(training_data_path / 'training_ready')\n",
    "    print(f'made directory {str(training_data_path / \"training_ready\")}')\n",
    "if not os.path.isdir(train_path):\n",
    "    os.mkdir(train_path)\n",
    "    print(f'made directory {str(train_path)}')\n",
    "if not os.path.isdir(val_path):\n",
    "    os.mkdir(val_path)\n",
    "    print(f'made directory {str(val_path)}')\n",
    "if not os.path.isdir(test_path):\n",
    "    os.mkdir(test_path)\n",
    "    print(f'made directory {str(test_path)}')\n",
    "    \n",
    "_, processed_list = get_list_of_ogg_files(unprocessed_path)\n",
    "\n",
    "# Get paths of notes and corresponding paths of spectrograms\n",
    "spec_paths = [song / 'spectrogram.npy' for song in processed_list]\n",
    "notes_paths = [song / 'notes_simplified.npy' for song in processed_list]\n",
    "\n",
    "\n",
    "# Used to create the outfile names of the saved slices\n",
    "# Will also be able to use these in conjunction with \"train_key\", \"test_key\", and \"val_key\"\n",
    "# to determine which indices go to which song\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "\n",
    "for i in tqdm(range(len(processed_list))):\n",
    "    # Process spectrogram\n",
    "    try:\n",
    "        spec = np.load(spec_paths[i])\n",
    "    except FileNotFoundError:\n",
    "        print('There is no spectrogram at {}'.format(spec_paths[i]))\n",
    "        continue\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "        print(traceback.format_exc())\n",
    "        continue\n",
    "    spec = __process_spectrogram(spec)\n",
    "\n",
    "    # Process notes\n",
    "    try:\n",
    "        notes = np.load(notes_paths[i])\n",
    "    except FileNotFoundError:\n",
    "        print('There is no notes_simplified at {}'.format(notes_paths[i]))\n",
    "        continue\n",
    "\n",
    "    assert notes.shape[0] == spec.shape[1], 'ERROR: Spectrogram and notes shape do not match'\n",
    "    \n",
    "    # Get number of segment_length second slices\n",
    "    num_slices = math.floor(spec.shape[1]/segment_length)\n",
    "    \n",
    "    # Split notes and spectrogram into bins\n",
    "    spec_bins = np.array([spec[:,j*segment_length:(j+1)*segment_length] for j in range(num_slices)])\n",
    "    notes_bins = np.array([notes[j*segment_length:(j+1)*segment_length] for j in range(num_slices)])\n",
    "    \n",
    "    # This list will hold the final note representations ready for the transformer\n",
    "    final_notes = []\n",
    "    for j in range(num_slices):\n",
    "        t_notes = __notes_to_output_space(notes_bins[j,:])\n",
    "        t_notes = __prepare_notes_tensor(t_notes)\n",
    "        final_notes.append(t_notes)\n",
    "    \n",
    "    # Randomly select whether it goes in train, val, or test based on the desired split\n",
    "    train_val_test_selection = np.random.choice(3, 1, p=train_val_test_probs)[0]\n",
    "    if train_val_test_selection == 0:\n",
    "        prepend_path = train_path\n",
    "    elif train_val_test_selection == 1:\n",
    "        prepend_path = val_path\n",
    "    else:\n",
    "        prepend_path = test_path\n",
    "\n",
    "    # Create a folder for the outfile\n",
    "    if not os.path.isdir(prepend_path / processed_list[i].stem): # Makes a folder with song name in correct subdirectory\n",
    "        os.mkdir(prepend_path / processed_list[i].stem)\n",
    "\n",
    "    if not COLAB:\n",
    "        for j in range(len(final_notes)):\n",
    "            spec_outfile = prepend_path / processed_list[i].stem / 'spectrograms' / (str(j) + '.npy')\n",
    "            if not os.path.isdir(spec_outfile.parent):\n",
    "                os.mkdir(spec_outfile.parent)\n",
    "\n",
    "            notes_outfile = prepend_path / processed_list[i].stem / 'notes' / (str(j) + '.npy') \n",
    "            if not os.path.isdir(notes_outfile.parent):\n",
    "                os.mkdir(notes_outfile.parent)\n",
    "\n",
    "            np.save(spec_outfile, spec_bins[j,...].astype('float16')) # change to float16 to reduce hard disk memory\n",
    "            np.save(notes_outfile, final_notes[j])\n",
    "    \n",
    "    else:\n",
    "        for j in range(len(final_notes)):\n",
    "            spec_outfile = prepend_path / processed_list[i].stem / 'spectrograms' / str(math.floor(j/40)) / (str(j) + '.npy')\n",
    "            if not os.path.isdir(spec_outfile.parent.parent):\n",
    "                os.mkdir(spec_outfile.parent.parent)\n",
    "            if not os.path.isdir(spec_outfile.parent):\n",
    "                os.mkdir(spec_outfile.parent)\n",
    "            \n",
    "            notes_outfile = prepend_path / processed_list[i].stem / 'notes' / str(math.floor(j/40)) / (str(j) + '.npy') \n",
    "            if not os.path.isdir(notes_outfile.parent.parent):\n",
    "                os.mkdir(notes_outfile.parent.parent)\n",
    "            if not os.path.isdir(notes_outfile.parent):\n",
    "                os.mkdir(notes_outfile.parent)\n",
    "\n",
    "            np.save(spec_outfile, spec_bins[j,...].astype('float16')) # change to float16 to reduce hard disk memory\n",
    "            np.save(notes_outfile, final_notes[j])\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_val_test_probs = [0.95, 0.025, 0.025]  # Probabilities of song being placed in [train, val, test]\n",
    "train_val_test_selection = np.random.choice(3, 1, p=train_val_test_probs)[0]\n",
    "print(train_val_test_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min_scalar_type(spec_bins[100, 300, 200])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
