{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prototypes the experiment inference pipeline for model 1 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For model 4 pre-sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing onsets...\n",
      "Generating Notes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_1\\Processing')\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_3')\n",
    "from m4_functions import *\n",
    "from m1_postprocessing import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For Model 1\n",
    "\n",
    "def get_test_song_paths(test_songs_dir):\n",
    "    '''\n",
    "    Parses the subdirectories of test_songs_dir and returns a list of paths to test_songs\n",
    "    '''\n",
    "    return [test_songs_dir / x for x in os.listdir(test_songs_dir)]\n",
    "\n",
    "test_songs = get_test_song_paths(Path.cwd() / 'Test_Songs')\n",
    "song_paths = [x / 'song.ogg' for x in test_songs]\n",
    "\n",
    "\n",
    "model_output_folder = 'm4_pre_sep'\n",
    "model_output_folder = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Experiments\\Generated_Songs') / model_output_folder\n",
    "# Loop through the songs in song_path and do inference\n",
    "for song in tqdm(song_paths):\n",
    "    metadata = {\n",
    "        'path_to_original_chart' : song.parent / 'notes.chart',\n",
    "        'path_to_original_notes_array' : song.parent / 'notes_simplified.npy'\n",
    "    }\n",
    "    song_name = str(song.parent).split('\\\\')[-1] \n",
    "    if not os.path.isdir(model_output_folder / song_name):\n",
    "        os.mkdir(model_output_folder / song_name)\n",
    "    if not os.path.isdir(model_output_folder / song_name / song_name):\n",
    "        os.mkdir(model_output_folder / song_name / song_name)\n",
    "\n",
    "    # Generate notes array here\n",
    "    notes_array = generate_song(song_path=song,\n",
    "                  outfile_song_name = 'Model 4 - ' + song_name,\n",
    "                  outfolder = model_output_folder / song_name / song_name)\n",
    "\n",
    "    # Save notes array and metadata\n",
    "    with open(str(model_output_folder / song_name / 'metadata.pkl'), 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    f.close()\n",
    "    np.save(str(model_output_folder / song_name / 'notes_array.npy'), notes_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For model 4 post-sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing onsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Notes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_1\\Processing')\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_3')\n",
    "from m4_functions import *\n",
    "from m1_postprocessing import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For Model 1\n",
    "\n",
    "def get_test_song_paths(test_songs_dir):\n",
    "    '''\n",
    "    Parses the subdirectories of test_songs_dir and returns a list of paths to test_songs\n",
    "    '''\n",
    "    return [test_songs_dir / x for x in os.listdir(test_songs_dir)]\n",
    "\n",
    "test_songs = get_test_song_paths(Path.cwd() / 'Test_Songs')\n",
    "song_paths = [x / 'separated.ogg' for x in test_songs]\n",
    "\n",
    "\n",
    "model_output_folder = 'm4_post_sep'\n",
    "model_output_folder = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Experiments\\Generated_Songs') / model_output_folder\n",
    "# Loop through the songs in song_path and do inference\n",
    "for song in tqdm(song_paths):\n",
    "    metadata = {\n",
    "        'path_to_original_chart' : song.parent / 'notes.chart',\n",
    "        'path_to_original_notes_array' : song.parent / 'notes_simplified.npy'\n",
    "    }\n",
    "    song_name = str(song.parent).split('\\\\')[-1] \n",
    "    if not os.path.isdir(model_output_folder / song_name):\n",
    "        os.mkdir(model_output_folder / song_name)\n",
    "    if not os.path.isdir(model_output_folder / song_name / song_name):\n",
    "        os.mkdir(model_output_folder / song_name / song_name)\n",
    "\n",
    "    # Generate notes array here\n",
    "    notes_array = generate_song(song_path=song,\n",
    "                  outfile_song_name = 'Model 4 sep - ' + song_name,\n",
    "                  outfolder = model_output_folder / song_name / song_name,\n",
    "                  original_song_path = song.parent / 'song.ogg')\n",
    "\n",
    "    # Save notes array and metadata\n",
    "    with open(str(model_output_folder / song_name / 'metadata.pkl'), 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    f.close()\n",
    "    np.save(str(model_output_folder / song_name / 'notes_array.npy'), notes_array)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For model 1 pre-sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_1\\Processing')\n",
    "sys.path.insert(1, r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_3')\n",
    "from m4_functions import *\n",
    "from m1_postprocessing import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# For Model 1\n",
    "\n",
    "def get_test_song_paths(test_songs_dir):\n",
    "    '''\n",
    "    Parses the subdirectories of test_songs_dir and returns a list of paths to test_songs\n",
    "    '''\n",
    "    return [test_songs_dir / x for x in os.listdir(test_songs_dir)]\n",
    "\n",
    "test_songs = get_test_song_paths(Path.cwd() / 'Test_Songs')\n",
    "song_paths = [x / 'song.ogg' for x in test_songs]\n",
    "\n",
    "def load_model(model_dir):\n",
    "    '''\n",
    "    Loads the PyTorch model and relevant information from model directory\n",
    "    '''\n",
    "    with open(str(model_dir / 'params.pkl'), 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Define model hyperparameters from params dictionary\n",
    "    trg_vocab_size = params['trg_vocab_size']\n",
    "    embedding_size = params['embedding_size']\n",
    "    num_heads = params['num_heads']\n",
    "    num_encoder_layers = params['num_encoder_layers']\n",
    "    num_decoder_layers = params['num_decoder_layers']\n",
    "    dropout = params['dropout']\n",
    "    max_len = params['max_src_len']\n",
    "    forward_expansion = params['embedding_size'] * params['forward_expansion']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        raise NameError('ERROR: cuda is not available')\n",
    "\n",
    "    model = Transformer(\n",
    "            embedding_size,\n",
    "            trg_vocab_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            device,\n",
    "        ).to(device)\n",
    "\n",
    "    # Load trained model    \n",
    "    model_file = os.listdir(model_dir)\n",
    "    model_file.remove('params.pkl')\n",
    "    model_file = model_file[0]\n",
    "    model.load_state_dict(torch.load(str(model_dir / model_file)))\n",
    "\n",
    "    return model, params, device\n",
    "\n",
    "model_dir = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Model_1\\saved models\\model10')\n",
    "model, params, device = load_model(model_dir)\n",
    "\n",
    "print(params)\n",
    "\n",
    "model_output_folder = 'm1_pre_sep'\n",
    "model_output_folder = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\tensor-hero\\Experiments\\Generated_Songs') / model_output_folder\n",
    "# Loop through the songs in song_path and do inference\n",
    "for song in song_paths:\n",
    "    metadata = {\n",
    "        'path_to_original_chart' : song.parent / 'notes.chart',\n",
    "        'path_to_original_notes_array' : song.parent / 'notes_simplified.npy'\n",
    "    }\n",
    "    song_name = str(song.parent).split('\\\\')[-1] \n",
    "    if not os.path.isdir(model_output_folder / song_name):\n",
    "        os.mkdir(model_output_folder / song_name)\n",
    "    if not os.path.isdir(model_output_folder / song_name / song_name):\n",
    "        os.mkdir(model_output_folder / song_name / song_name)\n",
    "    \n",
    "    song_metadata = {'Name' : params['model_name'] + song_name,\n",
    "                      'Artist' : 'Forrest',\n",
    "                      'Charter' : 'tensorhero',\n",
    "                      'Offset' : 0,\n",
    "                      'Resolution' : 192,\n",
    "                      'Genre' : 'electronic',\n",
    "                      'MediaType' : 'cd',\n",
    "                      'MusicStream' : 'song.ogg'}\n",
    "\n",
    "    notes_array = full_song_prediction(song_path=song,\n",
    "                                       model=model,\n",
    "                                       device=device,\n",
    "                                       sos_idx=432,\n",
    "                                       max_len=params['max_src_len'],\n",
    "                                       song_metadata=song_metadata,\n",
    "                                       outfolder=(model_output_folder / song_name / song_name))\n",
    "    \n",
    "    # Save notes array and metadata\n",
    "    with open(str(model_output_folder / song_name / 'metadata.pkl'), 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    f.close()\n",
    "    np.save(str(model_output_folder / song_name / 'notes_array.npy'), notes_array)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
