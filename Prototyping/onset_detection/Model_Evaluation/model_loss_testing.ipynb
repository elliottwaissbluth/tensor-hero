{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, r'/Users/scarr/MIMS/tensor-hero/Prototyping/onset_detection/Model_Evaluation')\n",
    "from mir_eval_function_onset_conversion import *\n",
    "from model_metric_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_original = np.load('/Users/scarr/MIMS/tensor-hero/example_song/notes_simplified.npy')\n",
    "notes_original_list = (notes_original[0:400],notes_original[401:800], notes_original[801:1200])\n",
    "notes_generated = np.load('/Users/scarr/MIMS/tensor-hero/example_song/notes_generated.npy')\n",
    "notes_generated_list = (notes_generated[0:400],notes_generated[401:800], notes_generated[801:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.array([1,2,3,1,2,4,0,1,3,2,1])\n",
    "searchval = 1\n",
    "ii = np.where(values == searchval)[0]\n",
    "\n",
    "values1 = np.array([2,2,3,2,2,4,0,1,3,2,1])\n",
    "# searchval1 = 3\n",
    "# iii = np.where(values1 == searchval1)\n",
    "sum(values1[ii] == searchval)/len(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(truth  , predicted):\n",
    "    losses =[]\n",
    "    mir_eval = eval_fmeas_precision_recall(onset_true=temp_true_onset, onset_estimate=temp_pred_onset, window=.05)  # returns [f_measure, precision, recall]\n",
    "    \n",
    "    #weight the precision\n",
    "\n",
    "    loss_precision = mir_eval[1]\n",
    "    \n",
    "    #weight the saturation\n",
    "    loss_saturation = freq_saturation(truth/predicted)\n",
    "\n",
    "    #weight the 1-5 inaccuracies, get list of accuracy for each incorrect single note\n",
    "    single_note_accuracy = []\n",
    "    for i in range(1,6):\n",
    "        searchval = i\n",
    "        i_s = np.where(truth == searchval)[0]\n",
    "        acc = sum(predicted[ii] == searchval)/len(ii)\n",
    "        single_note_accuracy.append(acc)\n",
    "\n",
    "    #weight the 1-5 inaccuracies, get list of accuracy for each incorrect single note\n",
    "    single_note_accuracy = []\n",
    "    for i in range(1,6):\n",
    "        searchval = i\n",
    "        i_s = np.where(truth == searchval)[0]\n",
    "        acc = sum(predicted[ii] == searchval)/len(ii)\n",
    "        single_note_accuracy.append(acc)\n",
    "        \n",
    "    #weight the double when should be single, triple when should be double, etc.\n",
    "\n",
    "\n",
    "    #take average of weighted losses\n",
    "    loss_value = np.mean(losses)\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
